{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sdsphd2021_intro_networks.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CALDISS-AAU/sdsphd21/blob/master/notebooks/sdsphd2021_intro_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBHEUT-gAGJX"
      },
      "source": [
        "# Preample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrlTmAczAN8t"
      },
      "source": [
        "## Import Standard Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KsZSo4HR4R8"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import itertools # Python's amazing iteration & combination library\n",
        "\n",
        "# For visualization\n",
        "!pip install -U bokeh\n",
        "!pip install -q holoviews"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf-HGknOmDph"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46t97DGZ1BNw"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGnDos9dAiZc"
      },
      "source": [
        "Welcome to your first part of the introduction to network analysis. In this session you will learn:\n",
        "\n",
        "1. Why applying network analysis is helpful to answer certain questions, and why framing certain contexts as networks gives new insights.\n",
        "2. The basic structure of relational data.\n",
        "3. How to construct graph objects from different datasources.\n",
        "4. How to analyse basic features of nodes, edges, and graphs.\n",
        "5. How to identify groups and communities in graphs.\n",
        "6. How to do simple network visualizations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7dHVt471EuG"
      },
      "source": [
        "## So what?\n",
        "So, before we talk about networks, one thing upfront... why should we? I mean, they undeniably look pretty, don't they? Somehow, the visualization of networks fascinates the human mind (find a short TED talk on networks and how they depict our world [here](https://www.ted.com/talks/manuel_lima_a_visual_history_of_human_knowledge)), and has even inspired an own art movement, networkism (see some examples [here](https://www.behance.net/gallery/184045/Links)). \n",
        "\n",
        "Yet, besides that, is there an analytical value for a data scientist to bother about networks?\n",
        "\n",
        "![](https://www.dropbox.com/s/b8x2iwhaxacheem/networks_google_apple.png?dl=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzCFGGoB1NNg"
      },
      "source": [
        "## The basic jargon\n",
        "\n",
        "First of all, what is a network? Plainly speaking, a network is a **system** of **elements** which are connected by some **relationship**. The vocabulary can be a bit technical and even inconsistent between different disciplines, packages, and software. \n",
        "\n",
        "The whole system is (surprise, surprise) usually called a **network** or **graph**. The elements are commonly referred to as **nodes** (system theory jargon) or **vertices** (graph theory jargon) of a graph, while the connections are **edges** or **links**. I will mostly refer to the elements as nodes, and their connections as edges.\n",
        "\n",
        "![](https://www.dropbox.com/s/ap0e5exjtvtohju/networks_network_illu.png?dl=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwXE5KHz1yib"
      },
      "source": [
        "Generally, networks are a form of representing **relational data**. This is a very general tool that can be applied to many different types of relationships between all kind of elements. The content, meaning, and interpretation for sure depends on what elements we display, and which types of relationships. For example:\n",
        "\n",
        "* In Social Network Analysis:\n",
        "     * Nodes represent actors (which can be persons, firms and other socially constructed entities)\n",
        "     * Edges represent relationships between this actors (friendship, interaction, co-affiliation, similarity ect.)\n",
        "* Other types of network\n",
        "     * Chemistry: Interaction between molecules\n",
        "     * Computer Science: The wirld-wide-web, inter- and intranet topologies\n",
        "     * Biology: Food-web, ant-hives\n",
        "\n",
        "The possibilities to depict relational data are manifold. For example:\n",
        "\n",
        "* Relations among persons\n",
        "     * Kinship: mother of, wife of...\n",
        "     * Other role based: boss of, supervisor of...\n",
        "     * Affective: likes, trusts...\n",
        "     * Interaction: give advice, talks to, retweets...\n",
        "     * Affiliation: belong to same clubs, shares same interests...\n",
        "* Relations among organizations\n",
        "     * As corporate entities, joint ventures, strategic alliances\n",
        "     * Buy from / sell to, leases to, outsources to\n",
        "     * Owns shares of, subsidiary of\n",
        "     * Via their members (Personnel flows, friendship...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9znlzEQ2kCN"
      },
      "source": [
        "# Relational data-structures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nj3Jw41Z2oAk"
      },
      "source": [
        "## Edgelist\n",
        "Most real world relational data is to be found in what we call an **edge list**, a dataframe that contains a minimum of two columns, one column of *nodes* that are the source of a connection and another column of nodes that are the target of the connection. The nodes in the data are identified by unique IDs.\n",
        "\n",
        "If the distinction between source and target is meaningful, the network is **directed**. If the distinction is not meaningful, the network is **undirected** (more on that later). So, every row that contains the ID of one element in column 1, and the ID of another element in column 2 indicates that a connection between them exists. \n",
        "\n",
        "An edge list can also contain additional columns that describe **attributes** of the edges such as a magnitude aspect for an edge. If the edges have a magnitude attribute the graph is considered **weighted** (e.g., number of interactions, strenght of friendship). \n",
        "\n",
        "Below an example ofa minimal edge list created with the `tibble()` function. In this case, let us assume this network to be unweighted, meaning a connection can be eiter tresent or absent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_FdxsZw2tfs"
      },
      "source": [
        "edge_list = [\n",
        "    ('A', 'B'),\n",
        "    ('B', 'C'),\n",
        "    ('A', 'C'),\n",
        "    ('C', 'D')\n",
        "]\n",
        "\n",
        "edge_list "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCKTbGpb3Z2a"
      },
      "source": [
        "## Adjacency Matrix\n",
        "\n",
        "A second popular form of network representation is the **adjacency-matrix** (also called **socio-matrix**). It is represented as a $n*n$ matrix, where $n$ stands for the number of elements of which their relationships should be represented. The value in the cell that intercepts row $n$ and column $m$ indicates if an edge is present (=1) or absent (=0).\n",
        "\n",
        "Tip: Given an edgelist, an adjacency matrix can easily be produced by crosstabulating:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP9nCGOg3ay7"
      },
      "source": [
        "adj_matrix = np.array([[0, 1, 1],\n",
        "                       [1, 0, 1],\n",
        "                       [1, 1, 0]])\n",
        "\n",
        "print(adj_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5DY8wZB3oHl"
      },
      "source": [
        "*Note:* Existing as well as not existing connections are stored. Since most networks in reality are **sparse** (= more potential connections are inactive than active), this is inneficient for storrage and computation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SmNLggd3pQp"
      },
      "source": [
        "from scipy.sparse import csr_matrix # for working with sparse matrices\n",
        "\n",
        "sparse_matrix = csr_matrix(adj_matrix)\n",
        "\n",
        "print(sparse_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3egNjZb532wc"
      },
      "source": [
        "## Nodelists\n",
        "Edgelists as well as adjacency matrices only stores connectivity pattern between nodes, but due to their structure cannot store informations on the nodes in which we might be interested. Therefore, we in many cases also provide a a **node list** with these informations (such as the names of the nodes or any kind of groupings)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_0lZrTL34TA"
      },
      "source": [
        "#node_list <- tibble(id = 1:5, \n",
        "#                    name = c(\"Jesper\", \"Pernille\", \"Jacob\", \"Dorte\", \"Donald\"),\n",
        "#                    gender = c(\"M\", \"F\", \"M\", \"F\", \"M\"),\n",
        "#                    group = c(\"A\", \"B\", \"B\", \"A\", \"C\"))\n",
        "#node_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ytfxuhzz3_VQ"
      },
      "source": [
        "## Graph Objects\n",
        "\n",
        "Up to now we see that relatonal data, and the analysis thereof, has some particularities, making it distinct from tabular data (e.g., dataframes), we usually work with. \n",
        "\n",
        "* Tabular data\n",
        "     * In tabular data, summary statistics of variables are **between observations** (column-wise) interdependent, meaning changing a value of some observation will change the corresponding variables summary statistics.\n",
        "     * LIkewise, variable values might be **within observation** interdependent (row-wise), meaning changing a variable value might change summary statistics of the observation\n",
        "     * Otherwise, values are (at least mathematically) independent.\n",
        "* Graph data\n",
        "     * Same holds true, but adittional interdependencies due to the relational structure of the data.\n",
        "     * Sepperation between **node** and **edge** data, which is interdependent. Removing a node might alos impy the removal of edges, removal of edges changes the characteristics of nodes\n",
        "     * In adittion, the relational structure makes that not only true for adjacent nodes and edges, but potentially multiple. Adding/Removing one node/edge could change the characteristics of every single other node/edge.\n",
        "     * That is less of a problem for local network characteristics (eg., a node's degree on level 1). However, many node and edge characteristics such\n",
        "     * That's mainly why graph computing is slightly more messy, and need own mathematical tools, and applications from graphical computing (graphical like graph, not like figure)\n",
        "\n",
        "![](https://www.dropbox.com/s/y9mp6yarctm7ysd/networks_data_structure.png?dl=1)\n",
        "\n",
        "Therefore, network analysis packages in `R`, `Python`, and elsewhere usually define own graph objects (containing information on nodes as well as edges), in which network data for further analysis is stored."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7_ks1PebEyz"
      },
      "source": [
        "We in the following will work with the [`networkx`](https://networkx.github.io/documentation/stable/index.html) library, which is the standard for network analysis in the Python community. Another popular package more from the graph-theorist community is [`igraph`](https://igraph.org/python/), which is also the main package used for network analysis in the `R` community. However, since `networkx` became the `Python` standard, we will in the following stick to it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCxardRxsfBL"
      },
      "source": [
        "### Graph concepts & terminology\n",
        "\n",
        "Before we start creating graphs, lets fix some more terminology related to graphs. Some of them might sound unintuitive by now, but we will come back to that later.\n",
        "\n",
        "* The vertices `u` and `v` are called the end vertices of the edge `(u,v)`\n",
        "* If two edges have the same end vertices they are `Parallel`\n",
        "* An edge of the form `(v,v)` is a `loop`\n",
        "* A Graph is `simple` if it has no parallel edges and loops\n",
        "* A Graph is said to be `Empty` if it has no edges. Meaning `E` is empty\n",
        "* A Graph is a `Null` Graph if it has no vertices. Meaning `V` and `E` is empty\n",
        "* Edges are `Adjacent` if they have a common vertex. Vertices are `Adjacent` if they have a common edge\n",
        "* The `degree` of the vertex `v`, written as `d(v)`, is the number of edges with v as an end vertex. By convention, we count a loop twice and parallel edges contribute separately\n",
        "* `Isolated` Vertices are vertices with degree 1.\n",
        "* A Graph is `Complete` or fully-connected if its edge set contains every possible edge between ALL of the vertices\n",
        "* A `Walk` in a Graph` G = (V,E)` is a finite, alternating sequence of the form  ViEiViEi  consisting of vertices and edges of the graph `G`\n",
        "* A `Walk` is `Open` if the initial and final vertices are different. A `Walk` is `Closed` if the initial and final vertices are the same\n",
        "* A `Walk` is a `Path` if ANY vertex is appear atmost once (Except for a closed walk)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqRDgOo0soxR"
      },
      "source": [
        "### Types of Graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdOGbsoSspIU"
      },
      "source": [
        "\n",
        "1. Weigthed vs. Unweighted\n",
        "2. Directed vs. Undirected\n",
        "3. Unimodal vs. Multimodal\n",
        "4. Unidimensional vs. Multidimensional\n",
        "\n",
        "`networkx` graph classes\n",
        "1. Graph\n",
        "2. DiGraph\n",
        "3. MultiGraph\n",
        "4. MultiDigraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmw1QRx-fvhm"
      },
      "source": [
        "### Creating a graph object\n",
        "\n",
        "The graph object forms the core of network analysis. This is the central place where nodes, edges, and their characteristics are jointly stored. Lets take a look how to create one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwA-31ceXiYI"
      },
      "source": [
        "# Import the library\n",
        "import networkx as nx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDrJpbhdZy99"
      },
      "source": [
        "# We can create a network graph G directly from the adjacency matrix.\n",
        "G = nx.from_numpy_array(adj_matrix)\n",
        "print(G.nodes(), G.edges())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxCfWKjraVqj"
      },
      "source": [
        "# We can also directly load an edgelist instead\n",
        "G = nx.from_edgelist(edge_list)\n",
        "print(G.nodes(), G.edges())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpEULOBzf_x5"
      },
      "source": [
        "# We can also create an own graph\n",
        "G = nx.Graph() # create an empty graph with no nodes and no edges\n",
        "print(G.nodes(), G.edges())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12qqqGLpgft2"
      },
      "source": [
        "G.add_nodes_from([1, 2, 3, 4, 5]) # add a list of nodes\n",
        "G.add_edges_from([(1,2), (1,3), (4,5), (5,3), (4,2), (3,2), (1,4)]) # add a list of edges\n",
        "print(G.nodes(), G.edges())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqqZGD7jjEs6"
      },
      "source": [
        "Ok, up to now that was pretty abstract, right? Lets plot the graph to get a feeling what the network looks like. We will explore this later more exhaustive. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpTFq32JiRww"
      },
      "source": [
        "nx.draw(G, with_labels=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg1KzjqNstKe"
      },
      "source": [
        "### Your turn!\n",
        "\n",
        "So, now its already time for a little exercise: Try to create and plot the following network structure. Have fun :)\n",
        "\n",
        "![](https://www.dropbox.com/s/88anz0w24kurckp/networks_mini_exercise.png?dl=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhW0QSjps6y1"
      },
      "source": [
        "G = nx.Graph()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEOTmdB7tIVu"
      },
      "source": [
        "G.add_nodes_from(['A', 'B', 'C', 'D', 'E']) # add a list of nodes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoHJdIZFtLOv"
      },
      "source": [
        "G.add_edges_from([('A', 'B'), ('A', 'C')]) # add a list of edges"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsCo0kBOtOkJ"
      },
      "source": [
        "nx.draw(G, with_labels=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAkiE7xj4dJL"
      },
      "source": [
        "# Network analysis and measures\n",
        "The reasons we are dealing with graph data in the first place is because we need some *graph-based algorithms* for solving our problem at hand. \n",
        "\n",
        "So, lets take a look at commonly used metrics to describe, characterize and analyse networks, nodes, and edges.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc2nv3hs6Vml"
      },
      "source": [
        "## Network data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jMn6fSRkLME"
      },
      "source": [
        "We now will load some sample data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUDRZMogm0Z1"
      },
      "source": [
        "G = nx.les_miserables_graph()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnoyVzzbm2UV"
      },
      "source": [
        "G.nodes()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StI62ALPm6HG"
      },
      "source": [
        "G.edges()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFJwxv70rLcr"
      },
      "source": [
        "print(nx.info(G))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nSfFALYrVD_"
      },
      "source": [
        "Lets take a first visual peek. For a non-trivial (not like the one before) visualization of networks, the way how nodes and edges are placed in the plot makes a big difference in terms of how informative the visualization is, and how much information we can get out of it. \n",
        "\n",
        "There are plenty of different algorithms to optimize node and edge positions in visualizations within a graph **layout**. [Here](https://networkx.github.io/documentation/stable/reference/drawing.html#module-networkx.drawing.layout) you find an overview over the ones implemented in `networkx`.\n",
        "\n",
        "We can usually render these layouts on the fly when plotting the graph object. Since these algorithms contain probabilistic and iterative elements, they might look slightly different from plot to plot, though. Since we will plot this network a couple of times during this tutorial and want to compare them among each others, we will create and save the layout already upfront and pass it every time to the plotting function to make sure that the nodes are always placed in the same position.\n",
        "\n",
        "Here, we use the *Fruchterman-Reingold* algorithm-one of the most commonly used ones-to create the layout."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iml84Gxhsewp"
      },
      "source": [
        "# Create and save a layout.\n",
        "G_layout = nx.layout.fruchterman_reingold_layout(G) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETu2jpXhrYOm"
      },
      "source": [
        "# We use the standard networkx plot, and pass the layout.\n",
        "nx.draw(G, pos = G_layout, with_labels=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCID7KZ57pkZ"
      },
      "source": [
        "Well, we somewhat an intuition of the network architecture, containing a core-region, and some periphral centers. Otherwise, it's rather uninformative. Good network visualization after all is more than just doing a standard plot, so there is much we can do to make it more informative. However, we get to that later. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfWDBV6koJ11"
      },
      "source": [
        "In this case, we have a weighted graph, meaning that an edge does not only exist or not, (binary), but rather weighted by the number of the nodes (representing characters) interaction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_rZqZHHw6wq"
      },
      "source": [
        "nx.get_edge_attributes(G, 'weight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-vgyQ-Jpb_8"
      },
      "source": [
        "We see that the edge weights vary quite a lot. For this simple example we will remove the weights to give us a undirected and unweighted graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyaIL1ishpBf"
      },
      "source": [
        "for n1, n2, d in G.edges(data=True):\n",
        "  d.pop('weight', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfaIautABXmm"
      },
      "source": [
        "We can even do better! We can use the powerful [`bokeh`](https://docs.bokeh.org/) library (we installed it in the preamble). However, it is very clunky to work with. The [`hollowviews`](http://holoviews.org/user_guide/Network_Graphs.html) library in turn provides a lightweight wrapper that enables us to produce pretty interactive visualizations with a few lines of code. Lets do that!\n",
        "\n",
        "PS: Try to hover over the nodes :-)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_QGbeK0ckBO"
      },
      "source": [
        "# Import the libraries and link to the bokeh backend\n",
        "import holoviews as hv\n",
        "from holoviews import opts\n",
        "hv.extension('bokeh')\n",
        "from bokeh.plotting import show\n",
        "\n",
        "# Setting the default figure size a bit larger\n",
        "defaults = dict(width=750, height=750, padding=0.1,\n",
        "                xaxis=None, yaxis=None)\n",
        "hv.opts.defaults(\n",
        "    opts.EdgePaths(**defaults), opts.Graph(**defaults), opts.Nodes(**defaults))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMCagH7ecnhA"
      },
      "source": [
        "g_plot = hv.Graph.from_networkx(G, G_layout).opts(tools=['hover'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SRjGNRxePJ_"
      },
      "source": [
        "show(hv.render(g_plot))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofu6yPAhkHJX"
      },
      "source": [
        "## Node-Level measures\n",
        "\n",
        "Often, we are interested in ways to summarize the pattern of node connectivity to infer something on their characteristics. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgLeHb234xe2"
      },
      "source": [
        "One of the simplest concepts when computing node level measures is that of **centrality**, i.e. how central is a node or edge in the graph. As this definition is inherently vague, a lot of different centrality scores exists that all treat the concept of \"central\" a bit different. \n",
        "\n",
        "We in the following well briefly illustrate the idea behind three of the most popular centrality measures, namely:\n",
        "\n",
        "* Degree centrality\n",
        "* Eigenvector centrality\n",
        "* Betweenness centrality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI72IKxj5EmR"
      },
      "source": [
        "### Degree centrality\n",
        "The degree centrality is probably the most intuitive node measure, which basically just counts the number of edges adjacent to a node.  Formally, the degree of node $i$ is the number of existing edges $e_{ij}$ with other nodes $j$ in a network with $n$ nodes:\n",
        "\n",
        "$$d_{ij} =\\sum\\limits_{j=1}^{n} e_{ij} ~ where: ~ i \\neq j$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOtpaAaj5GyR"
      },
      "source": [
        "cent_degree = dict(nx.degree(G))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81b_63tYB-u_"
      },
      "source": [
        "cent_degree.values()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwvI6GHAyBxZ"
      },
      "source": [
        "sorted(cent_degree.items(),key=lambda x:-x[1])[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wadHt2ihz_-y"
      },
      "source": [
        "![](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e6/Gavroche_%28Les_Misérables%29.jpg/162px-Gavroche_%28Les_Misérables%29.jpg)\n",
        "\n",
        "The most important character is *Valjean*, the main character, not that surprising. But the second most important character is *Gavroche*. Is that right? Lets have a look at the graph so we can see what is going on :-)\n",
        "\n",
        "**Note**: Node size represents degree centrality - Bigger nodes indicate degree centrality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj8I1TDQ-Opl"
      },
      "source": [
        "nx.set_node_attributes(G, cent_degree, 'cent_degree')\n",
        "\n",
        "g_plot = hv.Graph.from_networkx(G, G_layout).opts(tools=['hover'],\n",
        "                                                  node_size='cent_degree')\n",
        "\n",
        "show(hv.render(g_plot))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKj2lvYlytEI"
      },
      "source": [
        "nx.get_node_attributes(G,'cent_degree')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSYkNTiT5Nga"
      },
      "source": [
        "### Eigenvector centrality\n",
        "Similar to the degree centrality, the eigenvector centrality takes this idea of characterizing nodes by their importance in a network a step further. It also represents the main idea behind the pagerank algorithm (a variant of eigenvector centrality) that was powering Google Search in the beginning. \n",
        "\n",
        "The basic idea is to weight a node's degree centrality by the centrality of the nodes adjacent to it (and their centrality in turn by their centrality). This will make nodes connected to in turn also well connected nodes more important. The eigenvector here is just a clever mathematical trick to solve such a recurrent problem.\n",
        "\n",
        "$$x_{v}={\\frac {1}{\\lambda }}\\sum _{t\\in M(v)}x_{t}={\\frac {1}{\\lambda }}\\sum _{t\\in G}a_{v,t}x_{t}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Hye7Yv35WWG"
      },
      "source": [
        "cent_eigen = dict(nx.eigenvector_centrality(G))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elowp9sXDQC5"
      },
      "source": [
        "sorted(cent_eigen.items(),key=lambda x:-x[1])[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gweRnazJ4Qo5"
      },
      "source": [
        "for  i in cent_eigen:\n",
        "  cent_eigen[i] = cent_eigen[i]*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqScIFLvzUEU"
      },
      "source": [
        "nx.set_node_attributes(G, cent_eigen, 'cent_eigen')\n",
        "\n",
        "g_plot = hv.Graph.from_networkx(G, G_layout).opts(tools=['hover'],\n",
        "                                                  node_size='cent_eigen' )\n",
        "\n",
        "show(hv.render(g_plot))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iu8fk2z5d3l"
      },
      "source": [
        "### Betweenness centrality\n",
        "\n",
        "* The betweenness centrality of an object in a network measures the extent to which it lies on short paths\n",
        "* A higher betweenness indicates that it lies on more short paths and hence should somehow be important for traversing between different parts of a network\n",
        "* How many pairs of individuals would have to go through you in order to reach one another in the minimum number of hops? Who has higher betweenness, X or Y?\n",
        "\n",
        "In formulaic representation\n",
        "\n",
        "* The geodesic betweenness $B_{n}(i)$ of a **vertex** in a weighted, undirected network is\n",
        "$$B_{n}(i) =  \\sum_{s,t \\in G} \\frac{ \\Psi_{s,t}(i) }{\\Psi_{s,t}}$$\n",
        "where vertices $s,t,i$ are all different from each other\n",
        "\n",
        "* $\\Psi_{s,t}$ denotes the number of shortest paths (geodesics) between vertices $s$ and $t$\n",
        "* $\\Psi_{s,t}(i)$ denotes the number of shortest paths (geodesics) between vertices $s$ and $t$ **that pass through vertex** $i$.\n",
        "* The geodesic betweenness $B_n$ of a network is the mean of $B_n(i)$ over all vertices $i$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqbr1e-g5eVD"
      },
      "source": [
        "cent_between = nx.betweenness_centrality(G)\n",
        "sorted(cent_between.items(),key=lambda x:-x[1])[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXSI440J3lDI"
      },
      "source": [
        "for  i in cent_between:\n",
        "  cent_between[i] = cent_between[i]*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeWN2R_V0Zmo"
      },
      "source": [
        "nx.set_node_attributes(G, cent_between, 'cent_between')\n",
        "\n",
        "g_plot = hv.Graph.from_networkx(G, G_layout).opts(tools=['hover'],\n",
        "                                                  node_size='cent_between' )\n",
        "\n",
        "show(hv.render(g_plot))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NTLqJ576Jkn"
      },
      "source": [
        "## Neighborhood of a Node\n",
        "\n",
        "Further, we can look at the surrounding of a node, meaning the ones it is connected to, its **neighborhood**. Here, we can look at the **ego-network of a node**. That means how many nodes are in a certain **geodesic distance**, meaning the **shortest path**. Plainly speaking, how many nodes are not more than x-steps away.\n",
        "\n",
        "![](https://www.dropbox.com/s/yat7qsdfszmc1d1/networks_distance.jpg?dl=1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5rm3EtEcf7A"
      },
      "source": [
        "path = list(nx.all_shortest_paths(G, source=\"Valjean\", target=\"Tholomyes\"))\n",
        "print(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u419vA_qj0mL"
      },
      "source": [
        "print(list(G.neighbors(\"Valjean\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-tMbjbtlP1L"
      },
      "source": [
        "len(list(G.neighbors(\"Valjean\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JfR-011lHuG"
      },
      "source": [
        "def neighborhood(G, node, n):\n",
        "    path_lengths = nx.single_source_dijkstra_path_length(G, node)\n",
        "    return [node for node, length in path_lengths.items()\n",
        "                    if length == n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15MVrW7qlkmN"
      },
      "source": [
        "print(neighborhood(G, 'Valjean', 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZabNzslh5qRV"
      },
      "source": [
        "## Clustering (Community detection)\n",
        "\n",
        "Another common operation is to group nodes based on the graph topology, sometimes referred to as *community detection* based on its commonality in social network analysis.\n",
        "\n",
        "There are-just like for clustering of tabular data in UML-many different algorithms and approaches to detect and delineate communities. [Here](https://github.com/benedekrozemberczki/awesome-community-detection) you find a summary of currently used approaches.\n",
        "\n",
        "The main logic in most cases is to find ways to form groups which have a maximum *within-connectivity* and a minimum *between-connectivity*. Consequently, nodes in the same community should have a higher probability of being connected than nodes from different communities.\n",
        "\n",
        "Here we will use the **Louvain Method**, one of the most widely used community detection algorithms. It usually delivers good results, scales well, and can handle weighted networks. Furthermore, there is an actively maintained, easy to use Python implementation, [`python-louvain`](https://python-louvain.readthedocs.io).\n",
        "\n",
        "It optimises a quantity called modularity:\n",
        "\n",
        "$$  \\sum_{ij} (A_{ij} - \\lambda P_{ij}) \\delta(c_i,c_j) $$\n",
        "\n",
        "$A$ - The adjacency matrix\n",
        "\n",
        "$P_{ij}$ - The expected connection between $i$ and $j$.\n",
        "\n",
        "$\\lambda$ - Resolution parameter\n",
        "\n",
        "Can use lots of different forms for $P_{ij}$ but the standard one is the so called configuration model:\n",
        "\n",
        "$P_{ij} = \\frac{k_i k_j}{2m}$\n",
        "\n",
        "Loosely speaking, in an iterative process it \n",
        "\n",
        "1. You take a node and try to aggregate it to one of its neighbours.\n",
        "2. You choose the neighbour that maximizes a modularity function. This function tells you how connected is the community you are trying to attach your node to going to be if you actually attach your node to it (this function is easy to compute and this makes Louvain very fast!).\n",
        "3. Once you iterate through all the nodes, you will have merged few nodes together and formed some communities.\n",
        "4. This becomes the new input for the algorithm that will treat each community as a node and try to merge them together to create bigger communities.\n",
        "5. The algorithm stops when it's not possible to improve modularity any more. \n",
        "\n",
        "![](https://www.dropbox.com/s/afoeq2pa01lba50/networks_louvain.jpg?dl=1)\n",
        "\n",
        "This is the original paper, for those interested in further reads:\n",
        "\n",
        "* Blondel, Vincent D; Guillaume, Jean-Loup; Lambiotte, Renaud; Lefebvre, Etienne (9 October 2008). \"Fast unfolding of communities in large networks\". Journal of Statistical Mechanics: Theory and Experiment. 2008 (10): P10008\n",
        "\n",
        "Lets take a look how that works:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clVrDBbU5rYd"
      },
      "source": [
        "# Import libraries\n",
        "import community # `python-louvain` is implemented here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3EhiPkA6Mqe"
      },
      "source": [
        "# Find the optimal partition with the Louvain algorithm.\n",
        "com = community.best_partition(G)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuySDZyFRl06"
      },
      "source": [
        "# The number of communities detected\n",
        "max(com.values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxBtmmy6TVzf"
      },
      "source": [
        "nx.set_node_attributes(G, com, 'community')\n",
        "\n",
        "g_plot = hv.Graph.from_networkx(G, G_layout).opts(tools=['hover'],\n",
        "                                                  node_size='cent_degree', \n",
        "                                                  node_color='community', cmap=plt.cm.Set1,\n",
        "                                                  legend_position='right')\n",
        "\n",
        "show(hv.render(g_plot))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbvKwu316YAi"
      },
      "source": [
        "## (Global) Network structure\n",
        "\n",
        "Finally, it is often also informative to look at the overal characteristics of the network.\n",
        "\n",
        "\n",
        "The **density** of a measure represents the share of all connected to all possible connections in the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMxh4XgU6ZED"
      },
      "source": [
        "nx.density(G)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2KJssXl6eGM"
      },
      "source": [
        "**Transistivity**, also called the **Clustering Cefficient** indicates how much the network tends to be locally clustered. That is measured by the share of **closed triplets**. Again,w e will dig into that next time.\n",
        "\n",
        "![](https://www.dropbox.com/s/ei585dd6ysa243d/networks_ccoeff.png?dl=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVszFhkP6gbV"
      },
      "source": [
        "nx.transitivity(G)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipN2GYH96jq6"
      },
      "source": [
        "The **diameter** is the longest of the shortest paths between two nodes of the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxWMhcbI6mDE"
      },
      "source": [
        "nx.diameter(G)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oVTN1NF6sWP"
      },
      "source": [
        "Finally, the **mean distance**, or **average path lenght** represents the mean of all shortest paths between all nodes. It is a measure of diffusion potential within a network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uZW4bJ86s_U"
      },
      "source": [
        "nx.average_shortest_path_length(G)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5Cr0Ug12694"
      },
      "source": [
        "One more thing we didn't talk about yet: Small worlds.\n",
        "\n",
        "Small worlds are an interesting network structure, combining short path lenght betwen the nodes with a high clustering coefficient. That means, that we have small interconected clusters, which are in turn connected by **gatekeepers** (the edges we call **bridges** or **structural holes**). \n",
        "\n",
        "![](https://www.dropbox.com/s/q8n36748aodif8p/networks_smallworld2.jpg?dl=1)\n",
        "\n",
        "This leads to an interesting setup, which has proven to be conductive for efficient communication and fast diffusion of information in social networks.\n",
        "\n",
        "![](https://www.dropbox.com/s/43h8tl2ynbc784a/networks_smallworld1.jpg?dl=1)\n",
        "\n",
        "We calculate it for now in an easy way:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wZm88D_3OTa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV-EMPmStLnB"
      },
      "source": [
        "# Multi-Modal Networks\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IhBLLexCOPh"
      },
      "source": [
        "## What's that?\n",
        "Now its time to talk about an interesting type of networks, multi-modal. This means, a network has several \"modes\", meaning connects entities on different conceptual levels. The most commone one is a **2-mode** (or **bipartite**) network. \n",
        "\n",
        "Examples could be an \n",
        "\n",
        "* Author $\\rightarrow$ Paper\n",
        "* Inventor $\\rightarrow$ Patent\n",
        "* Member $\\rightarrow$ Club network. \n",
        "\n",
        "Here, the elements in the different modes represent different things. In interesting real-life research examples you find 2-mode networks for instance in co-occurence (2 actors mentioned in the same news-article), co-affiliation (2 actors are member of the same association), or co-characteristics (2 actors both like to talk about a certain topic on twitter)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rVL3iyWCOmY"
      },
      "source": [
        "## Network Projections\n",
        "\n",
        "Two-mode networks are rarely analysed in their original form. Although this is preferable, few methods exist for that purpose. As such, these networks are often transformed into one-mode networks (only one type of nodes) to be analysed. This procedure is often referred to as projection. Projection is done by selecting one of the sets of nodes and linking two nodes from that set if they were connected to the same node (of the other kind).\n",
        "\n",
        "We can alalyse them in sepperation (and sometimes we should), but often its helpful to *project* them onto one mode. Here, we create a node in one mode by joint association with another mode.\n",
        "\n",
        "2-mode\n",
        "\n",
        "![](https://toreopsahl.files.wordpress.com/2009/04/fig1_twomode_half.png)\n",
        "\n",
        "1-mode\n",
        "\n",
        "![](https://toreopsahl.files.wordpress.com/2009/04/fig1_twomode_simple.png)\n",
        "\n",
        "In my field, that often happens with scientometric data such as publications, but also patents or policy reports. Conceptually, we can see them as 2 mode networks, between articles and their reference. \n",
        "\n",
        "\n",
        "![](https://www.dropbox.com/s/e4vnq7kh24pyu0t/networks_2mode.png?dl=1)\n",
        "\n",
        "Particularly in citation networks, we can also use the implicite 2-mode structure of $Publications \\rightarrow Citation$\n",
        "\n",
        "That helps us to apply some interesting metrics, such as:\n",
        "\n",
        "* direct citations\n",
        "* Bibliographic coupling\n",
        "* Co--citations\n",
        "\n",
        "Interestingly, different projections of this 2-mode network give the whole resulting 1-mode network a different meaning.\n",
        "\n",
        "![](https://www.dropbox.com/s/f8g8nr83lucvpqx/networks_biblio.png?dl=1)\n",
        "\n",
        "For an application, check:\n",
        "\n",
        "* Rakas, M., & Hain, D. S. (2019). The state of innovation system research: What happens beneath the surface?. Research Policy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S92TTSjSr2jD"
      },
      "source": [
        "## Weighted Network Projection\n",
        "\n",
        "In a similar spirit as the method used by Newman (2001), it is also possible to discount for the number of nodes when projecting weighted two-mode networks.\n",
        "\n",
        " \n",
        " For example, it could be argued that if many online users post to a thread, their ties should be weaker than if there were few people posting to the thread. A straight forward generalisation is the following function: $w_{ij} = \\sum_p \\frac{w_{i,p}}{N_p - 1}$. \n",
        " \n",
        " This formula would create a directed one-mode network in which the out-strength of a node is equal to the sum of the weights attached to the ties in the two-mode network that originated from that node. For example, node C has a tie with a weight of 5 in the two-mode network and an out-strength of 5 in the one-mode projection.\n",
        "\n",
        "![](https://toreopsahl.files.wordpress.com/2009/04/fig1_twomode_forum_newman2001.png)\n",
        "\n",
        "* Newman, M. E. J., 2001. Scientific collaboration networks. II. Shortest paths, weighted networks, and centrality. Physical Review E 64, 016132."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqUNq8XA4Xfb"
      },
      "source": [
        "# Case Study: Directed Networks: Friends & Foes at Work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUGY4_tm6gKv"
      },
      "source": [
        "## Introduction to the case\n",
        "\n",
        "* Emmanuel Lazega, The Collegial Phenomenon: The Social Mechanisms of Cooperation Among Peers in a Corporate Law Partnership, Oxford University Press (2001).\n",
        "\n",
        "### Data \n",
        "This data set comes from a network study of corporate law partnership that was carried out in a Northeastern US corporate law firm, referred to as SG&R, 1988-1991 in New England. It includes (among others) measurements of networks among the 71 attorneys (partners and associates) of this firm, i.e. their strong-coworker network, advice network, friendship network, and indirect control networks. Various members' attributes are also part of the dataset, including seniority, formal status, office in which they work, gender, lawschool attended, individual performance measurements (hours worked, fees brought in), attitudes concerning various management policy options, etc. This dataset was used to identify social processes such as bounded solidarity, lateral control, quality control, knowledge sharing, balancing powers, regulation, etc. among peers.\n",
        "\n",
        "### Setting\n",
        "* What do corporate lawyers do? Litigation and corporate work.\n",
        "* Division of work and interdependencies.\n",
        "* Three offices, no departments, built-in pressures to grow, intake and assignment rules.\n",
        "* Partners and associates: hierarchy, up or out rule, billing targets.\n",
        "* Partnership agreement (sharing benefits equally, 90% exclusion rule, governance structure, elusive committee system) and incompleteness of the contracts.\n",
        "* Informal, unwritten rules (ex: no moonlighting, no investment in buildings, no nepotism, no borrowing to pay partners, etc.).\n",
        "* Huge incentives to behave opportunistically ; thus the dataset is appropriate for the study of social processes that make cooperation among rival partners possible. \n",
        "* Sociometric name generators used to elicit coworkers, advice, and 'friendship' ties at SG&R:\"Here is the list of all the members of your Firm.\"\n",
        "\n",
        "The networks where created according to the follwoing questionaire:\n",
        "\n",
        "* Strong coworkers network: \"Because most firms like yours are also organized very informally, it is difficult to get a clear idea of how the members really work together. Think back over the past year, consider all the lawyers in your Firm. Would you go through this list and check the names of those with whom you have worked with. By \"worked with\" I mean that you have spent time together on at least one case, that you have been assigned to the same case, that they read or used your work product or that you have read or used their work product; this includes professional work done within the Firm like Bar association work, administration, etc.\"\n",
        "* Basic advice network: \"Think back over the past year, consider all the lawyers in your Firm. To whom did you go for basic professional advice? For instance, you want to make sure that you are handling a case right, making a proper decision, and you want to consult someone whose professional opinions are in general of great value to you. By advice I do not mean simply technical advice.\"\n",
        "* 'Friendship' network:\n",
        "\"Would you go through this list, and check the names of those you socialize with outside work. You know their family, they know yours, for instance. I do not mean all the people you are simply on a friendly level with, or people you happen to meet at Firm functions.\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if1cPg6k6imS"
      },
      "source": [
        "## Data preperation\n",
        "\n",
        "###  Load the data\n",
        "\n",
        "Lets load the data! The three networks refer to cowork, friendship, and advice. The first 36 respondents are the partners in the firm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71deTXch7iSr"
      },
      "source": [
        "mat_friendship = pd.read_table(\"https://www.dropbox.com/s/0saiulir3pr566k/ELfriend.dat?dl=1\", delim_whitespace=True, header=None) \n",
        "mat_advice = pd.read_table(\"https://www.dropbox.com/s/apq42n1grim23k9/ELadv.dat?dl=1\", delim_whitespace=True, header=None) \n",
        "mat_work = pd.read_table(\"https://www.dropbox.com/s/dliz0sd7or8tv01/ELwork.dat?dl=1\", delim_whitespace=True, header=None)\n",
        "\n",
        "G_friendship = nx.from_pandas_adjacency(mat_friendship, create_using=nx.DiGraph)\n",
        "G_advice = nx.from_pandas_adjacency(mat_advice, create_using=nx.DiGraph)\n",
        "G_work = nx.from_pandas_adjacency(mat_work, create_using=nx.DiGraph)\n",
        "\n",
        "attributes = pd.read_table(\"https://www.dropbox.com/s/qz7fvfgx8lvjgpr/ELattr.dat?dl=1\", delim_whitespace=True, header=None, dtype='int') \n",
        "attributes=attributes.round().astype(int)\n",
        "attributes.columns = [\"id\", \"seniority\", \"gender\", \"office\", \"tenure\", \"age\", \"practice\", \"school\"]\n",
        "attributes.set_index('id',inplace=True)\n",
        "\n",
        "cleanup_nums = {\"seniority\":     {1: \"Partner\", 2: \"Associate\"},\n",
        "                \"gender\":     {1: \"Male\", 2: \"Female\"},\n",
        "                \"office\":     {1: \"Boston\", 2: \"Hartford\", 3:\"Providence\"},\n",
        "                \"practice\":     {1: \"Litigation\", 2: \"Corporate\"},\n",
        "                \"school\":     {1: \"Harvard, Yale\", 2: \"Ucon\", 3: \"Others\"}\n",
        "                } \n",
        "attributes.replace(cleanup_nums, inplace=True)\n",
        "\n",
        "attributes_dict=attributes.T.to_dict()\n",
        "\n",
        "nx.set_node_attributes(G_friendship, attributes_dict)\n",
        "nx.set_node_attributes(G_advice, attributes_dict)\n",
        "nx.set_node_attributes(G_work, attributes_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Goa-1DaY70QY"
      },
      "source": [
        "mat_friendship.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH9dm9YZ8ru6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4lHAAwP9Goe"
      },
      "source": [
        "print(nx.info(G_friendship))\n",
        "print(nx.info(G_advice))\n",
        "print(nx.info(G_work))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miuh7d9E_nG3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH8nopGQ_3HR"
      },
      "source": [
        "attributes.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zFKmoXi4COe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx1K_NQnAfew"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZZ5ZwpiDwvP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvvEtfmTPx2U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBnOo0PcQ7Eb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tYBSndBAoYN"
      },
      "source": [
        "attributes.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVdce7oftQNd"
      },
      "source": [
        "attributes.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLonGuH04SUz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij2063dwBRLo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHLLoXrhB_BP",
        "outputId": "85025d4a-5dd2-457f-b347-45c569b3dec9"
      },
      "source": [
        "print(nx.get_node_attributes(G_friendship, 'seniority'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'nx' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-10-aab186256c1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_node_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG_friendship\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'seniority'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m: name 'nx' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWsWIvDeMS3o"
      },
      "source": [
        "## Calculate dimensional centralities\n",
        "\n",
        "There might be better ways to do that (still experimenting), but for now lets first create centralities upfront for all networks. We for now only look at the in-degree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgkLkBk1YbXS"
      },
      "source": [
        "cent_degree_friendship = dict(G_friendship.in_degree)\n",
        "cent_degree_advice = dict(G_advice.in_degree)\n",
        "cent_degree_work = dict(G_work.in_degree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hJAhy_yY0Xq"
      },
      "source": [
        "nx.set_node_attributes(G_friendship, cent_degree_friendship, 'cent_degree')\n",
        "nx.set_node_attributes(G_advice, cent_degree_advice, 'cent_degree')\n",
        "nx.set_node_attributes(G_work, cent_degree_work, 'cent_degree')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88gPV3VKMxOT"
      },
      "source": [
        "# Create and save a layout.\n",
        "G_layout = nx.layout.kamada_kawai_layout(G_work)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6a5uk1rM8Yl"
      },
      "source": [
        "g_plot = hv.Graph.from_networkx(G_friendship, G_layout).opts(tools=['hover'],\n",
        "                                                                        directed=True,\n",
        "                                                                        edge_alpha=0.25,\n",
        "                                                                        node_size='cent_degree',\n",
        "                                                                        #node_color='seniority', cmap='Set1',\n",
        "                                                                        legend_position='right'\n",
        "                                                                        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z7c1f69p4bX"
      },
      "source": [
        "show(hv.render(g_plot))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXH5FO3BTEKz"
      },
      "source": [
        "g_plot = hv.Graph.from_networkx(G_advice, G_layout).opts(tools=['hover'],\n",
        "                                                                        directed=True,\n",
        "                                                                        edge_alpha=0.25,\n",
        "                                                                        node_size='cent_degree',\n",
        "                                                                        #node_color='cent_degree', cmap='Set1',\n",
        "                                                                        legend_position='right')\n",
        "show(hv.render(g_plot))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBtSaFIEcV6D"
      },
      "source": [
        "g_plot = hv.Graph.from_networkx(G_work, G_layout).opts(tools=['hover'],\n",
        "                                                                        directed=True,\n",
        "                                                                        edge_alpha=0.25,\n",
        "                                                                        node_size='cent_degree',\n",
        "                                                                        #node_color='seniority', cmap='Set1',\n",
        "                                                                        legend_position='right')\n",
        "show(hv.render(g_plot))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWKHXIc5skJL"
      },
      "source": [
        "nx.attribute_assortativity_coefficient(G_friendship, 'seniority')\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvmBMVQm7vnK"
      },
      "source": [
        "## Assortiativity\n",
        "\n",
        "We can also calculate another interested measure, particularly in social networks: Assortiativity. In a nutshell, it measures if two nodes that share certain characteristics ahve a higher or lower probability to be connected.\n",
        "\n",
        "For details, check:\n",
        "\n",
        "* Newman, M. E. J. (27 February 2003). \"Mixing patterns in networks\". Physical Review E. American Physical Society (APS). 67 (2): 026126"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4gz_Wbg7UZT"
      },
      "source": [
        "nx.attribute_assortativity_coefficient(G_friendship, 'school')\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK9n01K47d_D"
      },
      "source": [
        "nx.attribute_assortativity_coefficient(G_friendship, 'office')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbOzP1X_71pH"
      },
      "source": [
        "## Reciprocity\n",
        "\n",
        "Anotyher interesting question usually is, if directed edges are reciptocated, meaning that an edge between `i,j` makes an edge between `j,i` more likely"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unMN2vQp7_Ka"
      },
      "source": [
        "nx.overall_reciprocity(G_friendship)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqeSwph-jFth"
      },
      "source": [
        "# Your turn!\n",
        "\n",
        "Explore the network a biut further.\n",
        "\n",
        "1. Calculate the reciprocity for the work and advise network. Are the numbers diffetrent? Why might that be the case?\n",
        "2. Identify communities in the friendship and advice network (hint: works only on undirected networks, so you might have to create an undirected graph)\n",
        "3. Visualize these communities (static or dynamic)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3TsHTeMjIXU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHO1FbZjeoNS"
      },
      "source": [
        "# Case Study in 2-Mode Networks: Exploring Instagram Hashtag Networks "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc76DE6ho1tl"
      },
      "source": [
        "In this notebook, we will collect data from Instagram to construct (snowball) a network of hashtags as well as a (2-mode) bipartite network of Instagram users and hashtags.\n",
        "\n",
        "The networks in this example can be considered synthetic, since nodes and particularly edges represent virtual constructs rather than explicit connections.\n",
        "\n",
        "\n",
        "In this case we explore\n",
        "\n",
        "- Graph construction (normal and bipartite)\n",
        "- Calculation of centrality indicators \n",
        "- Community detection\n",
        "- Projection of bipartite network\n",
        "\n",
        "Furthermore you will learn:\n",
        "\n",
        "- to make simple (public) API requests (API: Application Programming Interface) \n",
        "- parse json response\n",
        "- perform simple string manipulation/text-mining to extract features of interest (Transition into NLP)\n",
        "\n",
        "## So what?\n",
        "\n",
        "Such an analysis can be useful in marketing to identify sub-dicussions in a niche or related to a brand. We will detect popular hashtags within sub-niches that \"correlate\" with a topic of interest.\n",
        "Furthermore, we will identify accounts with high engagement (post-counts) within specific hashtag communities.\n",
        "\n",
        "Unfortunately Instagram, very recently (few days back), diesabled a simple public API that allowed to map usernames form user-ids. Therefore, we will use ```instaloader```, a module for interacting with Instagram. \n",
        "\n",
        "We will only use public data that does not require log-in. If you want to explore other graph structures on Instagram (e.g. follow-networks), have a look at Instabot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC69HN1Zj6E-"
      },
      "source": [
        "## Tooling Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zGmpK9sgCiv"
      },
      "source": [
        "# Installing instaloader\n",
        "!pip3 install instaloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zj9L7Gqj-Jq"
      },
      "source": [
        "import requests as rq # The requests library handles \"requests\" to APIs similar to a browser that requests a webpage given a URL\n",
        "\n",
        "#from nltk.tokenize import TweetTokenizer # A bit of a transition into NLP. The tweet tokenizer from the NLTK library will help us extract the hashtags from post-text\n",
        "#tknzr = TweetTokenizer()\n",
        "\n",
        "from networkx.algorithms import bipartite # bipartite NW algos\n",
        "\n",
        "# Instaloader for mapping user-ids to usernames\n",
        "#import instaloader\n",
        "#L = instaloader.Instaloader()\n",
        "\n",
        "import itertools # Python's amazing iteration & combination library"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTW9x4HWkzeN"
      },
      "source": [
        "## Getting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXnEZKBBk19D"
      },
      "source": [
        "# Defining global constants for the instagram extract\n",
        "\n",
        "# Note: These things may change without a warning...\n",
        "\n",
        "# Instagram base url preffix\n",
        "tagurl_prefix = 'https://www.instagram.com/explore/tags/'\n",
        "\n",
        "# suffix to append to tag request url to retrieve data in JSON format\n",
        "tagurl_suffix = '/?__a=1'\n",
        "\n",
        "# suffix to end cursor when requesting posts by tag\n",
        "tagurl_endcursor = '&max_id='\n",
        "\n",
        "# a generic media post preffix (concat with media shortcode to view)\n",
        "posturl_prefix = 'https://www.instagram.com/p/'\n",
        "\n",
        "# target initial tags (we will run this with only one tag but the code can take multiple - just extend the list)\n",
        "tags = ['machinelearning']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSDCpB8HlEic"
      },
      "source": [
        "# urls to initial tags using the above url-components\n",
        "queries = [ tagurl_prefix + tag + tagurl_suffix for tag in tags ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsraq-CVlInF"
      },
      "source": [
        "The response structure of this Insta endpoint is not really straightforward. You can read more about it in the original post.\n",
        "The data is most likely composed on request by some large-scale graph database at returned. Instagram obviously assumes that the receiving site is a browser exploring public posts.\n",
        "\n",
        "We also don't get all posts for some hashtag right away but a \"page\" ~25 posts.\n",
        "\n",
        "To receive further posts, we need to pass a new requests specifying \"our position\" by providing an end_cursor.\n",
        "\n",
        "This **end cursor** can be found in\n",
        "\n",
        "```\n",
        "response['graphql']['hashtag']['edge_hashtag_to_media']['page_info']['end_cursor']\n",
        "```\n",
        "\n",
        "#### Some thoughts on JSON\n",
        "\n",
        "This brings us to JSON. Think of JSON objects as of combinations of dictionaries and lists that can contain most Python objects (e.g. lists, dictionaries, tuples, strings, ints etc.) that can be represented as text. Once parsed you can operate JSON objects just as any other dictionary or list in Python.\n",
        "More about JSON - here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxWmgj5Elo8C",
        "outputId": "c74c4fde-200b-4d0e-fc00-8ce6523cf64a"
      },
      "source": [
        "# # Doesnt work anymore... new instagram scraping blocker?\n",
        "edges = []\n",
        "for q in queries:    \n",
        "    for i in range(10): # how many iterations/deepth ?\n",
        "        r = rq.get(q).json()\n",
        "        end_cursor = r['graphql']['hashtag']['edge_hashtag_to_media']['page_info']['end_cursor']\n",
        "        edges.extend(r['graphql']['hashtag']['edge_hashtag_to_media']['edges'])\n",
        "        print(i)\n",
        "        q = q + tagurl_endcursor + end_cursor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_cuG-gcltjM",
        "outputId": "dca27ef4-662f-4830-e5c5-6579788af304"
      },
      "source": [
        "# workaround, pre-loaded instagram data\n",
        "# Here we just C&P the text output when following the 'query' link in a txt or json (doesnt matter, as long as it is unformatted text) file.\n",
        "!wget \"https://github.com/SDS-AAU/SDS-master/raw/master/00_data/insta_ml.json\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NacQ8ntt6zOI"
      },
      "source": [
        "# We can now read it\n",
        "res = open('insta_ml.json').read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XG1Ei7U7EUV"
      },
      "source": [
        "# And load it as a json\n",
        "import json\n",
        "res = json.loads(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQVq0U0NmD-K"
      },
      "source": [
        "edges = []\n",
        "edges.extend(res['graphql']['hashtag']['edge_hashtag_to_media']['edges'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kOa1gndmOFn"
      },
      "source": [
        "### Bringing the collected data into useful format...\n",
        "\n",
        "In the next step we will take the rich raw posts data and extract only the information that we need for our analysis. We will just cut out owner-id (account that posted), a shortcode that we can use to identify the post and get more data on it in future if needed, and the text including the hashtags.\n",
        "\n",
        "To make things more compact we not only extract the raw data but we also preprocess a bit.\n",
        "\n",
        "The hashtags are incorporated within the post-text. Therefore, we pass the text of each post through a tokenizer, that identifies individual words and elements (such as emoji). We use the tweet-tokenizer from the NLTK library, which is made for working with social media data.\n",
        "\n",
        "```\n",
        "  tokens = tknzr.tokenize(text)\n",
        "  tags = [x.strip('#') for x in tokens if x.startswith('#')]\n",
        "```\n",
        "\n",
        "The first line turns the text of the post in a list of tokens (words & co.). The second line picks out only the elements that start with a \"#\" and strips the \"#\" when adding them to a list.\n",
        "\n",
        "Then we construct a dictionary with these values and append it to a list.\n",
        "\n",
        "This gives us a list of dicitonaries - something that we can pass to Pandas to get a dataframe we can work with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLB5-d0MmSnJ"
      },
      "source": [
        "post_dicts = [] #empty list\n",
        "\n",
        "for post in edges: #iterate all raw posts\n",
        "\n",
        "  if post['node']['edge_media_to_caption']['edges'] == []: # hop to the next if no text in the post\n",
        "    continue\n",
        "    \n",
        "  post_dict = {} # empty dictionary\n",
        "  id_owner = post['node']['owner']['id'] # pick out user-id\n",
        "  shortcode = post['node']['shortcode'] # pick out short post identifier\n",
        "  text = post['node']['edge_media_to_caption']['edges'][0]['node']['text'] # pick out post text\n",
        "  \n",
        "  # Pick hashtags from text\n",
        "  tokens = tknzr.tokenize(text)\n",
        "  tags = [x.strip('#') for x in tokens if x.startswith('#')]\n",
        "\n",
        "  # fill in dictionary with values\n",
        "  post_dict['id_owner'] = id_owner\n",
        "  post_dict['shortcode'] = shortcode\n",
        "  post_dict['tags'] = tags\n",
        "  post_dict['text'] = text\n",
        "\n",
        "  post_dicts.append(post_dict) #append the dictionary to a list of post-dictionaries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuFU900mmXR4"
      },
      "source": [
        "# Create DF\n",
        "posts_df = pd.DataFrame(post_dicts)\n",
        "\n",
        "# Remove hashtags that are not a hashtag (emptyspace & mistakes)\n",
        "posts_df['tags'] = posts_df['tags'].map(lambda t: [x for x in t if x.isalnum()])\n",
        "\n",
        "# Kick out posts with 0 hashtags\n",
        "posts_df = posts_df[posts_df['tags'].map(len) != 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4kqyvYhmyd_"
      },
      "source": [
        "## Simple stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JtUU0lpm2GK"
      },
      "source": [
        "# People with most posts\n",
        "posts_df['id_owner'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MR5PK1sm8bi"
      },
      "source": [
        "# Look up who these people are (this line gets us also other information about the user)\n",
        "profile = instaloader.Profile.from_id(L.context, 7649963444)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOqy3qp7nBjM"
      },
      "source": [
        "profile.username"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWfAvaXFnSEV"
      },
      "source": [
        "## Creating a graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvajlu8nV_r"
      },
      "source": [
        "# Create empty undirected Graph\n",
        "G = nx.Graph()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjWyh-drniSY"
      },
      "source": [
        "We will construct the graph from hashtag combinations of each post. We will use `itertools.combinations` for that. Given a list of n objects this will create all possible unique combinations of size k (which we set to 2). Note, that we can build up the Graph sequentially. An edgelist contains all data we need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUCvoXLPnntE"
      },
      "source": [
        "# Create the graph\n",
        "for i in posts_df['tags']:\n",
        "  G.add_edges_from(list(itertools.combinations(i,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaSxzFs8nr3M"
      },
      "source": [
        "## Preprocessing the Graph\n",
        "\n",
        "It can be a good idea to filter the Graph before analysing. For instance, we can remove all hashtags with low degree-centrality. This can be interpreted as - kicking out made up hashtags or extremely underused ones. We will calculate a percentile threshold and exclude everything under it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blJ6C4AvpGv0"
      },
      "source": [
        "# Calculating degree centrality for the Graph\n",
        "degree_centrality = nx.degree_centrality(G)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAlIKUr3of_O"
      },
      "source": [
        "# Getting a \"reasonable\" lower bound.\n",
        "perc_filter = np.percentile([v for u,v in degree_centrality.items()], 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au-USbGFpc9Q"
      },
      "source": [
        "# Make a subgraph based on nodes with a degree_centrality over the threshold\n",
        "nodes_selected = [x for x,y in degree_centrality.items() if y >= perc_filter]\n",
        "\n",
        "G = G.subgraph(nodes_selected)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooXLo_41phk_"
      },
      "source": [
        "## Analysing the Graph\n",
        "\n",
        "Now we are going to calculate some network indicators and once done, we will export a DataFrame analyse them further."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Xwd4O-cppH3"
      },
      "source": [
        "# Recalculate degre-centrality and assign it as a node-attribute\n",
        "degree_centrality = nx.degree_centrality(G)\n",
        "nx.set_node_attributes(G, degree_centrality, 'degree')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MkEa6JTp5R_"
      },
      "source": [
        "# Same for Eigenvector Centrality\n",
        "eigenvector = nx.eigenvector_centrality(G)\n",
        "nx.set_node_attributes(G, eigenvector, 'eigenvector_centrality')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpoDGJWVp9JR"
      },
      "source": [
        "# Same for community detection\n",
        "communities = community.best_partition(G, resolution = 1)\n",
        "nx.set_node_attributes(G, communities, 'community')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP40ZvkKqKjt"
      },
      "source": [
        "graph_df = pd.DataFrame(dict(G.nodes(data=True))).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAv4aUqlqOfG"
      },
      "source": [
        "graph_df['community'].value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySIF9zuJqXaV"
      },
      "source": [
        "# Find the 5 most popular hashtags for each identified community\n",
        "tag_per_com = graph_df.groupby('community')['degree'].nlargest(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAP193Fnqa93"
      },
      "source": [
        "tag_per_com[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbuGwJokqgz_"
      },
      "source": [
        "# Let's write the graph out to play around with it in Gephi\n",
        "nx.write_gexf(G, 'G_hashtags.gexf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2t613TVq2gz"
      },
      "source": [
        "## Bipartite graph between users and hashtags\n",
        "\n",
        "Can we identify communities of users given their usage of hashtags?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0Hsp858q7Wl"
      },
      "source": [
        "# Create a new graph\n",
        "B = nx.Graph()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnFCi91Qq-qY"
      },
      "source": [
        "# we will take the same data\n",
        "posts_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5ubVoHqrGwV"
      },
      "source": [
        "# We need to specify the nodes for level 0 - this will be our users\n",
        "B.add_nodes_from(list(set(posts_df.id_owner)), bipartite=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUfNc8fcrMVC"
      },
      "source": [
        "# Then we need to add hashtags nodes as level 1 nodes\n",
        "B.add_nodes_from(list(set(itertools.chain(*posts_df.tags))), bipartite=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cR8aomMrSLo"
      },
      "source": [
        "# This quick loop will generate edges between users and hashtags\n",
        "# Every time someone mentions a #hashtag, a link is created\n",
        "\n",
        "bi_edges = []\n",
        "for i in posts_df[['id_owner','tags']].iterrows(): # we do this row-by-row since each row is a post\n",
        "  id_owner = i[1]['id_owner']\n",
        "  for j in i[1]['tags']:\n",
        "    bi_edges.append((id_owner, j)) # edges are appended to a list as a tuple (id_owner, hashtag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVC_LlLQrVwY"
      },
      "source": [
        "# Let's add the edges to our graph\n",
        "B.add_edges_from(bi_edges)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpCpRAUNraVb"
      },
      "source": [
        "In the next step we will project the graph onto the account-level. For this we need to get the nodesets of the 0 level. We also calculate the level 1 level (just because)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3udCf_grbOx"
      },
      "source": [
        "# Extract a set of nodes with level 0\n",
        "top_nodes = {n for n, d in B.nodes(data=True) if d['bipartite']==0}\n",
        "\n",
        "# the remaining nodes are then level 1\n",
        "bottom_nodes = set(B) - top_nodes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmj9qejNrfeU"
      },
      "source": [
        "# Let's project this graph using a weighted projection\n",
        "G_proj = bipartite.weighted_projected_graph(B, top_nodes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMAjRJimrkWO"
      },
      "source": [
        "# Again, we can identify communities\n",
        "bi_communities = community.best_partition(G_proj, resolution = 1)\n",
        "nx.set_node_attributes(G_proj, bi_communities, 'community')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioxp2gqErndc"
      },
      "source": [
        "# Calculate eigenvector centrality and set it as an attribute\n",
        "bi_eigenvector = nx.eigenvector_centrality(G_proj)\n",
        "nx.set_node_attributes(G_proj, bi_eigenvector, 'eigenvector_centrality')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVkT_RngrrLm"
      },
      "source": [
        "# Create a new attribute \"activity\" - or propensity to spam\n",
        "nx.set_node_attributes(G_proj, dict(posts_df.id_owner.value_counts()), 'activity' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8TcvXvIrwY7"
      },
      "source": [
        "# Do spammers connect more in terms of spamming about the same stuff?\n",
        "print(nx.numeric_assortativity_coefficient(G_proj,'activity'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLOQvqbBr3xl"
      },
      "source": [
        "graph_proj_df = pd.DataFrame(dict(G_proj.nodes(data=True))).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPo9xiKbr6XE"
      },
      "source": [
        "graph_proj_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvTnZKd3r8i-"
      },
      "source": [
        "# Find the 5 most central for each identified community\n",
        "user_per_com = graph_proj_df.groupby('community')['eigenvector_centrality'].nlargest(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN1BB-_isAFw"
      },
      "source": [
        "user_per_com"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2Bc5R1IsGJB"
      },
      "source": [
        "profile = instaloader.Profile.from_id(L.context, 12055605293)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnFW80aesMuW"
      },
      "source": [
        "print(profile.biography)\n",
        "print(profile.username)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_lIdGzKsS7P"
      },
      "source": [
        "nx.write_gexf(G_proj, 'G_proj.gexf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmlRyNy9ZsiU"
      },
      "source": [
        "## Your turn!\n",
        "\n",
        "Basically, try to repeat the exercise on your own with a term of your choice. \n",
        "\n",
        "1. Just run the code from before, where you replace 'machinelearning' with whatever discussion you are interested to map.\n",
        "2. Create the query link as in the notebook.\n",
        "3. Since the instaloader is not working at the moment (seems to be blocked), you have to click on the query link to get the output in your web-browser. C&P it then, and save it in a text file (something like the text editor. that saves unformatted text.)\n",
        "4. Now you can analyse the  instagram network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsHpyANjaQdX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}